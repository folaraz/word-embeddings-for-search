{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "from nltk import ngrams\n",
    "import gc\n",
    "\n",
    "\n",
    "def load_doc(file):\n",
    "    text = open(file, 'r').read()\n",
    "    return text\n",
    "\n",
    "def get_sentences(file):\n",
    "    doc = load_doc(file)\n",
    "    sentences = sent_tokenize(doc)\n",
    "    return sentences\n",
    "\n",
    "def clean_doc(file):\n",
    "    docs = get_sentences(file)\n",
    "    result = []\n",
    "    for doc in docs:\n",
    "        doc = doc.replace('--', ' ')\n",
    "        tokens = doc.split()\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "        result.append(tokens)\n",
    "    return result\n",
    "\n",
    "def get_phrase_vec(model,tok_sent):\n",
    "    numerator = np.zeros(300)\n",
    "    for word in tok_sent:\n",
    "        try:\n",
    "            vec = model[word]\n",
    "        except Exception as e:\n",
    "            vec = np.zeros(300)\n",
    "        numerator += vec\n",
    "    return numerator/len(tok_sent)\n",
    "        \n",
    "def avg_sentence( model,file):\n",
    "    c_docs = clean_doc(file)\n",
    "    sent_vec = []\n",
    "    for doc in c_docs:\n",
    "        numerator = np.zeros(300)\n",
    "        denominator = 0\n",
    "        for word in doc:\n",
    "            try:\n",
    "                vec = model[word]\n",
    "            except KeyError as e:\n",
    "                vec = np.zeros(300)\n",
    "            numerator += vec\n",
    "        sent_vec.append((doc,numerator/len(doc)))\n",
    "    return sent_vec\n",
    "\n",
    "def search_word(model, input_word,textFile,Phrase=True):\n",
    "    vector_sentences = avg_sentence(model,textFile)\n",
    "    if Phrase:\n",
    "        word_vec = get_phrase_vec(model, input_word.split(' '))\n",
    "    else:\n",
    "        try:\n",
    "            word_vec = model[input_word]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(\"Word not present in the vocabulary\")\n",
    "    n = 0\n",
    "    ans = []\n",
    "    for vec in vector_sentences:\n",
    "        calc_vec = list(cosine_similarity(word_vec.reshape(1, -1),vec[1].reshape(1, -1)))[0][0]\n",
    "        ans.append((' '.join(vec[0]),calc_vec))\n",
    "    sent_with_highest_signal = sorted(ans, key = lambda x: x[1])[-1][0]\n",
    "    uni_to_trigrams = [(' '.join(c),cosine_similarity(get_phrase_vec(model,c).reshape(1,-1),word_vec.reshape(1,-1))[0][0])\n",
    "                                         for i in range(1,4) for c in ngrams(sent_with_highest_signal.split(),i)]\n",
    "    print('-----------------------------THE MAIN SENTENCE------------------------------------------------------')\n",
    "    print(sent_with_highest_signal)\n",
    "    print('-----------------------------THE NGRAMS ALONGSIDE THEIR RESPECTIVE SCORES---------------------------')\n",
    "    return sorted(uni_to_trigrams, key = lambda x: x[1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model=KeyedVectors.load_word2vec_format(\"/Users/abdulrazzaq/gensim-data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------THE MAIN SENTENCE------------------------------------------------------\n",
      "the firm has a market cap of billion a pe ratio of and a beta of\n",
      "-----------------------------THE NGRAMS ALONGSIDE THEIR RESPECTIVE SCORES---------------------------\n",
      "[('and a beta', 0.31662712170703106), ('a beta of', 0.31662712170703106), ('beta', 0.31662712170703117), ('a beta', 0.31662712170703117), ('beta of', 0.31662712170703117)]\n"
     ]
    }
   ],
   "source": [
    "ans = search_word(model,'uber about to ipo','article.txt',Phrase=True)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
